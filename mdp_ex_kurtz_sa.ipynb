{
 "metadata": {
  "name": "",
  "signature": "sha256:e16d554cb4089d7b2ef09d0574d573ecc5c684613601a60b0cdefada464dca62"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division, print_function\n",
      "import numpy as np\n",
      "import scipy.sparse as sparse\n",
      "import itertools\n",
      "from mdp_sa import MDP_sa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Markov Decision Processes: Example 1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We study the decision problem of Colonel Kurtz\n",
      "as described in Economic Dynamics: Theory and Computation, Section 5.1:\n",
      "* the production is drawn from the uniform distribution on $\\{0, \\ldots, B\\}$;\n",
      "* the storage is limited by $M$;\n",
      "* the stock is equal to the storage from the last period plus the production in the current period;\n",
      "* some part of the stock is consumed and the other is stored (up to $M$);\n",
      "* the flow utility is given by $u(c) = c^{\\alpha}$, where $c$ is the consumption; and\n",
      "* the discount factor is $\\beta \\in [0, 1)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Following the textbook,\n",
      "we take the stock as the state variable $i$ and the storage as the action (control) variable $a$\n",
      "(of course one may take the consumption as the action).\n",
      "Then,\n",
      "* the state space is $S = \\{0, \\ldots, M + B\\}$: the number of states is $n = M + B + 1$;\n",
      "* the action space is $A = \\{0, \\ldots, M\\}$: the number of actions is $m = M + 1$; and\n",
      "* the set of feasible actions when the current state is $i$ is\n",
      "  $\\Gamma(i) = \\{0, \\ldots, i \\wedge M\\}$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Formulation with State-Action Pairs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This formulation represents the reward function and the probability transition function\n",
      "by a vector of length $L$ and an array of shape $(L, n)$,\n",
      "where $L$ is the number of feasible state-action pairs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we have to list feasible state-action pairs.\n",
      "In the current implementation, the MDP_sa class requires\n",
      "* an array containing state indices: `[0, 1, 1, 2, 2, 2, ...]`; and\n",
      "* an array containing action indices: `[0, 0, 1, 0, 1, 2, ...]`.\n",
      "\n",
      "Infeasible state-action pairs are excluded here."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Kurtz' decision problem is then described by\n",
      "* the length $L$ reward vector `R`,\n",
      "  where, for state-action pair $i = (s, a)$, \n",
      "  `R[i]` is the reward of `a` when the state is `s`;\n",
      "* the $L \\times n$ transition probability array `Q`,\n",
      "  where, for state-action pair $i = (s, a)$,\n",
      "  `Q[i, s']` is the probability that the state in the next period is `s'`\n",
      "  when the current state is `s` and the action chosen is `a`; and\n",
      "* the discount factor `beta`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, the Bellman equation is:\n",
      "$$\n",
      "v[s] = \\max \\{R[i] + \\beta \\sum_{s'=0}^{n-1} Q[i, s'] v[s'] \\mid i = (s, a)\n",
      "\\text{ for some $a \\in \\Gamma(s)$}\\}.\n",
      "$$\n",
      "We want to solve this to obtain\n",
      "the optimal value function $v^{\\ast}$, the optimal policy function $\\sigma^{\\ast}$,\n",
      "and the resulting controlled Markov chain."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use the parameter values as specified in Listing 5.1 on page 104."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "B, M = 10, 5\n",
      "n, m = M + B + 1, M + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Construction of state and action indices\n",
      "L = 0\n",
      "for i in range(n):\n",
      "    L += np.minimum(i, M) + 1\n",
      "\n",
      "s_indices, a_indices = np.empty(L, dtype=int), np.empty(L, dtype=int)\n",
      "sa = 0\n",
      "for s, a in itertools.product(range(n), range(m)):\n",
      "    if a <= np.minimum(s, M):\n",
      "        s_indices[sa], a_indices[sa] = s, a\n",
      "        sa += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(L)  # Number of state-action pairs\n",
      "print(s_indices[:27])\n",
      "print(a_indices[:27])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "81\n",
        "[0 1 1 2 2 2 3 3 3 3 4 4 4 4 4 5 5 5 5 5 5 6 6 6 6 6 6]\n",
        "[0 0 1 0 1 2 0 1 2 3 0 1 2 3 4 0 1 2 3 4 5 0 1 2 3 4 5]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Construction of the reward vector and the transition probability array\n",
      "R = np.empty(L)\n",
      "Q = sparse.lil_matrix((L, n))\n",
      "alpha = 0.5\n",
      "prob = np.array([1/(B+1) for i in range(B+1)])\n",
      "\n",
      "it = np.nditer((s_indices, a_indices), flags=['c_index'])\n",
      "for s, a in it:\n",
      "    R[it.index] = (s - a)**(alpha)\n",
      "    Q[it.index, a:a+(B+1)] = prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(R)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.          1.          0.          1.41421356  1.          0.\n",
        "  1.73205081  1.41421356  1.          0.          2.          1.73205081\n",
        "  1.41421356  1.          0.          2.23606798  2.          1.73205081\n",
        "  1.41421356  1.          0.          2.44948974  2.23606798  2.\n",
        "  1.73205081  1.41421356  1.          2.64575131  2.44948974  2.23606798\n",
        "  2.          1.73205081  1.41421356  2.82842712  2.64575131  2.44948974\n",
        "  2.23606798  2.          1.73205081  3.          2.82842712  2.64575131\n",
        "  2.44948974  2.23606798  2.          3.16227766  3.          2.82842712\n",
        "  2.64575131  2.44948974  2.23606798  3.31662479  3.16227766  3.\n",
        "  2.82842712  2.64575131  2.44948974  3.46410162  3.31662479  3.16227766\n",
        "  3.          2.82842712  2.64575131  3.60555128  3.46410162  3.31662479\n",
        "  3.16227766  3.          2.82842712  3.74165739  3.60555128  3.46410162\n",
        "  3.31662479  3.16227766  3.          3.87298335  3.74165739  3.60555128\n",
        "  3.46410162  3.31662479  3.16227766]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(Q[0].toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.          0.\n",
        "   0.          0.          0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Discount factor\n",
      "beta = 0.9"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now construct an MDP:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdp = MDP_sa(R, Q, beta, s_indices, a_indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Solving the Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us solve the problem."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we solve by policy iteration:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v, sigma, mc, num_iter = mdp.solve(method='policy_iteration', return_num_iter=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Number of iterations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_iter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optimal policy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sigma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "array([0, 0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 5, 5, 5, 5])"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Value function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "array([ 19.01740222,  20.01740222,  20.43161578,  20.74945302,\n",
        "        21.04078099,  21.30873018,  21.54479816,  21.76928181,\n",
        "        21.98270358,  22.18824323,  22.3845048 ,  22.57807736,\n",
        "        22.76109127,  22.94376708,  23.11533996,  23.27761762])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optimal average values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(1 - mdp.beta) * v"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([ 1.90174022,  2.00174022,  2.04316158,  2.0749453 ,  2.1040781 ,\n",
        "        2.13087302,  2.15447982,  2.17692818,  2.19827036,  2.21882432,\n",
        "        2.23845048,  2.25780774,  2.27610913,  2.29437671,  2.311534  ,\n",
        "        2.32776176])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check that the controlled Markov chain is irreducible and aperiodic:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mc.is_irreducible and mc.is_aperiodic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Expected average value:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mc.stationary_distributions[0].dot((1 - mdp.beta) * v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "2.1673779353215252"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Comparison of the Solution Methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compare the solution by value iteration with accuracy $\\varepsilon = 0.01$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epsilon = 1e-2\n",
      "\n",
      "v1, sigma1, mc1, num_iter1 = \\\n",
      "    mdp.solve(method='value_iteration', epsilon=epsilon, return_num_iter=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Number of iterations (default maximum number = 100):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_iter1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "79"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chech that the correct policy is returned:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.array_equal(sigma1, sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Devition of the output value from that of policy iteration:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.abs(v1 - v).max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "0.0046441762624702676"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Modified policy iteration:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v2, sigma2, mc2, num_iter2 = \\\n",
      "    mdp.solve(method='modified_policy_iteration', epsilon=epsilon, return_num_iter=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Number of iterations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_iter2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chech that the correct policy is returned:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.array_equal(sigma1, sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Devition of the output value from that of policy iteration:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.abs(v2 - v).max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "0.0013784675327599416"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compare the perfomance:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epsilon = 1e-2\n",
      "methods = ['value_iteration', 'policy_iteration', 'modified_policy_iteration']\n",
      "\n",
      "for method in methods:\n",
      "    print(method)\n",
      "    %timeit mdp.solve(method=method, epsilon=epsilon)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "value_iteration\n",
        "100 loops, best of 3: 2.56 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "policy_iteration\n",
        "100 loops, best of 3: 3.44 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "modified_policy_iteration\n",
        "100 loops, best of 3: 2.33 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Notes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`s_indices` and `a_indices` may be ordered arbitrarily;\n",
      "they will internally be sorted in a lexicographic order."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s_indices, a_indices = np.empty(L, dtype=int), np.empty(L, dtype=int)\n",
      "sa = 0\n",
      "for s, a in itertools.product(range(n), range(m)):\n",
      "    if a <= np.minimum(s, M):\n",
      "        s_indices[sa], a_indices[sa] = s, a\n",
      "        sa += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Shuffle s_indices and a_indices randomly\n",
      "x = np.arange(L)\n",
      "np.random.shuffle(x)\n",
      "s_indices, a_indices = s_indices[x], a_indices[x]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(s_indices[:16])\n",
      "print(a_indices[:16])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[11  5  7  2 15  3 11 13  1 12  5 10  4  5  9 11]\n",
        "[2 5 2 0 1 0 3 4 0 2 3 2 2 1 2 5]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Construction of the reward vector and the transition probability array\n",
      "R = np.empty(L)\n",
      "Q = sparse.lil_matrix((L, n))\n",
      "alpha = 0.5\n",
      "prob = np.array([1/(B+1) for i in range(B+1)])\n",
      "\n",
      "it = np.nditer((s_indices, a_indices), flags=['c_index'])\n",
      "for s, a in it:\n",
      "    R[it.index] = (s - a)**(alpha)\n",
      "    Q[it.index, a:a+(B+1)] = prob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(R)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 3.          0.          2.23606798  1.41421356  3.74165739  1.73205081\n",
        "  2.82842712  3.          1.          3.16227766  1.41421356  2.82842712\n",
        "  1.41421356  2.          2.64575131  2.44948974  3.31662479  2.\n",
        "  1.41421356  2.23606798  3.          2.23606798  3.          1.\n",
        "  3.46410162  3.16227766  2.64575131  2.          2.44948974  1.          0.\n",
        "  2.          3.74165739  2.82842712  2.44948974  3.16227766  3.46410162\n",
        "  2.23606798  1.          1.41421356  2.64575131  2.82842712  2.64575131\n",
        "  0.          1.          0.          2.64575131  2.82842712  3.31662479\n",
        "  2.44948974  3.60555128  3.          1.          3.60555128  3.31662479\n",
        "  3.87298335  0.          0.          2.23606798  1.73205081  2.\n",
        "  3.16227766  1.73205081  3.31662479  3.60555128  1.73205081  2.\n",
        "  2.82842712  3.46410162  2.44948974  1.41421356  3.31662479  2.64575131\n",
        "  3.46410162  3.16227766  2.44948974  2.23606798  1.73205081  3.16227766\n",
        "  1.73205081  3.        ]\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(Q[0].toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.          0.          0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.          0.          0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdp = MDP_sa(R, Q, beta, s_indices, a_indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(mdp.s_indices)\n",
      "print(mdp.a_indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0  1  1  2  2  2  3  3  3  3  4  4  4  4  4  5  5  5  5  5  5  6  6  6  6\n",
        "  6  6  7  7  7  7  7  7  8  8  8  8  8  8  9  9  9  9  9  9 10 10 10 10 10\n",
        " 10 11 11 11 11 11 11 12 12 12 12 12 12 13 13 13 13 13 13 14 14 14 14 14 14\n",
        " 15 15 15 15 15 15]\n",
        "[0 0 1 0 1 2 0 1 2 3 0 1 2 3 4 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3\n",
        " 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4\n",
        " 5 0 1 2 3 4 5]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(mdp.R)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.          1.          0.          1.41421356  1.          0.\n",
        "  1.73205081  1.41421356  1.          0.          2.          1.73205081\n",
        "  1.41421356  1.          0.          2.23606798  2.          1.73205081\n",
        "  1.41421356  1.          0.          2.44948974  2.23606798  2.\n",
        "  1.73205081  1.41421356  1.          2.64575131  2.44948974  2.23606798\n",
        "  2.          1.73205081  1.41421356  2.82842712  2.64575131  2.44948974\n",
        "  2.23606798  2.          1.73205081  3.          2.82842712  2.64575131\n",
        "  2.44948974  2.23606798  2.          3.16227766  3.          2.82842712\n",
        "  2.64575131  2.44948974  2.23606798  3.31662479  3.16227766  3.\n",
        "  2.82842712  2.64575131  2.44948974  3.46410162  3.31662479  3.16227766\n",
        "  3.          2.82842712  2.64575131  3.60555128  3.46410162  3.31662479\n",
        "  3.16227766  3.          2.82842712  3.74165739  3.60555128  3.46410162\n",
        "  3.31662479  3.16227766  3.          3.87298335  3.74165739  3.60555128\n",
        "  3.46410162  3.31662479  3.16227766]\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(mdp.Q[0].toarray())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.          0.\n",
        "   0.          0.          0.        ]]\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}